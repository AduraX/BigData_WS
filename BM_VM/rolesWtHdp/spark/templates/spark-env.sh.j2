#!/usr/bin/env bash

SPARK_HOME={{proj_dir}}/spark
SPARK_LOCAL_IP={{ spark_local_ip }}     # the IP address Spark binds to on this node
SPARK_LOCAL_DIRS={{ spark_local_dirs }} # | join(',')
SPARK_WORKER_DIR={{ spark_worker_dir }}

SPARK_MASTER_HOST={{ spark_master_host }}       # to bind the master to a different IP address or hostname
SPARK_WORKER_CORES={{ spark_worker_cores }}     # to set the number of cores to use on this machine
SPARK_WORKER_MEMORY={{ spark_worker_memory }}    # to set how much total memory workers have to give executors (e.g. 1000m, 2g)
SPARK_WORKER_OPTS="{{ spark_worker_opts }}"     # See: https://spark.apache.org/docs/latest/spark-standalone.html

OPENBLAS_NUM_THREADS={{ spark_openblas_num_threads }}  # disable multi-threading of OpenBLAS (because Spark should be keeping CPUs busy)
